{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import third-party modules\n",
    "import nifti_roi.nifti_roi as nro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Command():\n",
    "    '''\n",
    "    Creates a command and an empty command list for UNIX command line programs/applications. Primary use and\n",
    "    use-cases are intended for the subprocess module and its associated classes (i.e. call/run).\n",
    "    Attributes:\n",
    "        command: Command to be performed on the command line\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init doc-string for Command class.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def init_cmd(self, command):\n",
    "        '''\n",
    "        Init command function for initializing commands to be used on UNIX command line.\n",
    "        \n",
    "        Arguments:\n",
    "            command (string): Command to be used. Note: command used must be in system path\n",
    "        Returns:\n",
    "            cmd_list (list): Mutable list that can be appended to.\n",
    "        '''\n",
    "        self.command = command\n",
    "        self.cmd_list = [f\"{self.command}\"]\n",
    "        return self.cmd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cmd_list,stdout=\"\",stderr=\"\"):\n",
    "    '''\n",
    "    Uses python's built-in subprocess class to run a command from an input command list.\n",
    "    The standard output and error can optionally be written to file.\n",
    "    \n",
    "    Arguments:\n",
    "        cmd_list(list): Input command list to be run from the UNIX command line.\n",
    "        stdout(file): Output file to write standard output to.\n",
    "        stderr(file): Output file to write standard error to.\n",
    "    Returns:\n",
    "        stdout(file): Output file that contains the standard output.\n",
    "        stderr(file): Output file that contains the standard error.\n",
    "    '''\n",
    "    if stdout and stderr:\n",
    "        with open(stdout,\"w\") as file:\n",
    "            with open(stderr,\"w\") as file_err:\n",
    "                subprocess.call(cmd_list,stdout=file,stderr=file_err)\n",
    "                file.close(); file_err.close()\n",
    "    elif stdout:\n",
    "        with open(stdout,\"w\") as file:\n",
    "            subprocess.call(cmd_list,stdout=file)\n",
    "            file.close()\n",
    "        stderr = None\n",
    "    else:\n",
    "        subprocess.call(cmd_list)\n",
    "        stdout = None\n",
    "        stderr = None\n",
    "\n",
    "    return stdout,stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hemi_labels(file,wb_struct,map_number=1):\n",
    "    '''\n",
    "    Loads left or right hemisphere of CIFTI dlabel (dense label) file.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input CIFTI dlabel file\n",
    "        wb_struct(str): Structure - valid inputs are either: CORTEX_LEFT or CORTEX_RIGHT\n",
    "        map_number(int): Map number of the input CIFTI dlabel map\n",
    "    Returns:\n",
    "        atlas_data(numpy array): Numpy array of labeled surface vertices for some specific hemisphere\n",
    "        atlas_dict(dict): Dictionary of label IDs to ROI names\n",
    "    '''\n",
    "    \n",
    "    gii_label = 'data.label.gii'\n",
    "    \n",
    "    load_label = Command().init_cmd(\"wb_command\"); load_label.append(\"-cifti-separate\")\n",
    "    \n",
    "    load_label.append(file)\n",
    "    load_label.append(\"COLUMN\")\n",
    "    load_label.append(\"-label\"); load_label.append(wb_struct)\n",
    "    load_label.append(gii_label)\n",
    "    \n",
    "    run(load_label)\n",
    "    \n",
    "    gifti_img = nib.load(gii_label)\n",
    "    \n",
    "    atlas_data = gifti_img.get_arrays_from_intent('NIFTI_INTENT_LABEL')[map_number-1].data\n",
    "    atlas_dict = gifti_img.get_labeltable().get_labels_as_dict()\n",
    "    \n",
    "    os.remove(gii_label)\n",
    "    \n",
    "    return atlas_data,atlas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gii_data(file,intent='NIFTI_INTENT_NORMAL'):\n",
    "    '''\n",
    "    Loads GIFTI surface/metric data (.func or .shape) and stores the \n",
    "    data as NxMxP numpy array - in which N = X dimensions, M = Y \n",
    "    dimensions, and P = the number of TRs or timepoints of the input \n",
    "    GIFTI data.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input GIFTI surface/metric file\n",
    "        intent(str): File read intention for nibabel i/o module\n",
    "    Returns:\n",
    "        data(numpy array): Numpy array of data for GIFTI file\n",
    "    '''\n",
    "    \n",
    "    # Load surface data\n",
    "    surf_dist_nib = nib.load(file)\n",
    "    \n",
    "    # Number of TRs in data\n",
    "    num_da = surf_dist_nib.numDA\n",
    "    \n",
    "    # Read all arrays and concatenate temporally\n",
    "    array1 = surf_dist_nib.get_arrays_from_intent(intent)[0]\n",
    "    \n",
    "    data = array1.data\n",
    "    \n",
    "    if num_da >= 1:\n",
    "        for da in range(1,num_da):\n",
    "            data = np.vstack((data,surf_dist_nib.get_arrays_from_intent(intent)[da].data))\n",
    "            \n",
    "    # Transpose data such that vertices are organized by TR\n",
    "    data = np.transpose(data)\n",
    "    \n",
    "    # If output is 1D, make it 2D\n",
    "    if len(data.shape) == 1:\n",
    "        data = data.reshape(data.shape[0],1)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hemi_data(file,wb_struct):\n",
    "    '''\n",
    "    Wrapper function for `load_gii_data`:\n",
    "    Loads GIFTI surface/metric data (.func or .shape) and stores the \n",
    "    data as NxMxP numpy array - in which N = X dimensions, M = Y \n",
    "    dimensions, and P = the number of TRs or timepoints of the input \n",
    "    GIFTI data.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input GIFTI surface/metric file\n",
    "        wb_struct(str): Structure - valid inputs are either: CORTEX_LEFT or CORTEX_RIGHT\n",
    "    Returns:\n",
    "        data(numpy array): Numpy array of data for GIFTI file\n",
    "    '''\n",
    "    \n",
    "    gii_data = 'data.func.gii'\n",
    "    \n",
    "    load_gii = Command().init_cmd(\"wb_command\"); load_gii.append(\"-cifti-separate\")\n",
    "    \n",
    "    load_gii.append(file)\n",
    "    load_gii.append(\"COLUMN\")\n",
    "    load_gii.append(\"-metric\"); load_gii.append(wb_struct)\n",
    "    load_gii.append(gii_data)\n",
    "    \n",
    "    run(load_gii)\n",
    "    \n",
    "    data = load_gii_data(gii_data)\n",
    "    \n",
    "    os.remove(gii_data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_name(cluster_data,atlas_data,atlas_dict):\n",
    "    '''\n",
    "    Finds ROI names from overlapping clusters on the cortical surface via\n",
    "    vertex matching.\n",
    "    \n",
    "    Arguments:\n",
    "        cluster_data(numpy array): Input CIFTI dlabel file\n",
    "        atlas_data(numpy array): Numpy array of labeled surface vertices for some specific hemisphere\n",
    "        atlas_dict(dict): Dictionary of label IDs to ROI names\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs overlapped by cluster(s)\n",
    "    '''\n",
    "    \n",
    "    # for idx,val in enumerate(cluster_data.astype(int)):\n",
    "    for idx,val in enumerate(cluster_data):\n",
    "        if cluster_data[idx] == 0:\n",
    "            atlas_data[idx] = 0\n",
    "    \n",
    "    tmp_list = list()\n",
    "    roi_list = list()\n",
    "    \n",
    "    for i in np.unique(atlas_data)[1:]:\n",
    "        # print(atlas_dict[i])\n",
    "        tmp_list = atlas_dict[i]\n",
    "        roi_list.append(tmp_list)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters(file,left_surf,right_surf,thresh = 1.77,distance = 20):\n",
    "    '''\n",
    "    Loads left or right hemisphere of CIFTI dscalar (dense scalar) file and identifies clusters\n",
    "    and returns a numpy array of the clusters' vertices.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input CIFTI dscalar file\n",
    "        left_surf(file): Left surface file (preferably midthickness file)\n",
    "        right_surf(file): Rigth surface file (preferably midthickness file)\n",
    "        thresh(float): Threshold values below this value\n",
    "        distance(float): Minimum distance between two or more clusters\n",
    "    Returns:\n",
    "        cii_data(numpy array): Numpy array of surface vertices\n",
    "    '''\n",
    "    \n",
    "    cii_data = 'clusters.dscalar.nii'\n",
    "    \n",
    "    thresh = str(thresh)\n",
    "    distance = str(distance)\n",
    "    \n",
    "    find_cluster = Command().init_cmd(\"wb_command\"); find_cluster.append(\"-cifti-find-clusters\")\n",
    "    find_cluster.append(file)\n",
    "    find_cluster.append(thresh); find_cluster.append(distance)\n",
    "    find_cluster.append(thresh); find_cluster.append(distance)\n",
    "    find_cluster.append(\"COLUMN\")\n",
    "    find_cluster.append(cii_data)\n",
    "    find_cluster.append(\"-left-surface\")\n",
    "    find_cluster.append(left_surf)\n",
    "    find_cluster.append(\"-right-surface\")\n",
    "    find_cluster.append(right_surf)\n",
    "    \n",
    "    run(find_cluster)\n",
    "    \n",
    "    return cii_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spread(file,out_file,roi_list):\n",
    "    '''\n",
    "    Writes the contents or roi_list to a spreadsheet.\n",
    "    \n",
    "    Arguments:\n",
    "        file (file): Input CIFTI file\n",
    "        out_file (file): Output csv file name and path. This file need not exist at runtime.\n",
    "        roi_list(list): List of ROIs to write to file\n",
    "    Returns: \n",
    "        out_file (csv file): Output csv file name and path.\n",
    "    '''\n",
    "    \n",
    "    # Strip csv file extension from output file name\n",
    "    if '.csv' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    elif '.tsv' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    elif '.txt' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Construct image dictionary\n",
    "    file = os.path.abspath(file)\n",
    "    img_dict = {\"File\":file,\n",
    "         \"ROIs\":[roi_list]}\n",
    "    \n",
    "    # Create dataframe from image dictionary\n",
    "    df = pd.DataFrame.from_dict(img_dict,orient='columns')\n",
    "    \n",
    "    # Write output CSV file\n",
    "    if os.path.exists(out_file):\n",
    "        df.to_csv(out_file, sep=\",\", header=False, index=False, mode='a')\n",
    "    else:\n",
    "        df.to_csv(out_file, sep=\",\", header=True, index=False, mode='w')\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_hemi(gii_data, gii_atlas, wb_struct):\n",
    "    '''\n",
    "    Wrapper function for `load_hemi_labels`, `load_hemi_data`, and `get_roi_name`:\n",
    "    \n",
    "    Loads GIFTI data to find the names or ROIs that overlap with clusters for some hemisphere\n",
    "    \n",
    "    Arguments:\n",
    "        gii_data(file): Input GIFTI file\n",
    "        gii_atlas(file): Input GIFTI atlas label file\n",
    "        wb_struct(str): Structure - valid inputs are either: CORTEX_LEFT or CORTEX_RIGHT\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs that overlap with CIFTI cluster\n",
    "    '''\n",
    "       \n",
    "    \n",
    "    # Get atlas information\n",
    "    [atlas_data,atlas_dict] = load_hemi_labels(gii_atlas,wb_struct)\n",
    "    \n",
    "    # Get cluster data\n",
    "    cluster_data = load_hemi_data(gii_data, wb_struct)\n",
    "    \n",
    "    # Get ROI names from overlapping cluster(s)\n",
    "    roi_list = get_roi_name(cluster_data,atlas_data,atlas_dict)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def roi_loc(coords,vol_atlas=\"Harvard-Oxford Subcortical Structural Atlas\"):\n",
    "#     '''\n",
    "#     Uses input list of X,Y,Z MNI space mm coordinates to identify ROIs.\n",
    "    \n",
    "#     NOTE: External bash script is used. Atlas option is hard-coded.\n",
    "    \n",
    "#     Arguments:\n",
    "#         coords(list): Coordinate list with a lenth of 3 that corresponds to the XYZ coordinates of some ROI in MNI space.\n",
    "#         vol_atlas(str): Atlas to be used in FSL's `atlasquery`. See FSL's `atlasquery` help menu for details.\n",
    "        \n",
    "#     Returns:\n",
    "#         roi_list(list): List of ROIs generated from input coordinates.\n",
    "#     '''\n",
    "    \n",
    "#     roi_list = list()\n",
    "#     out_file = \"subcort.rois.txt\"\n",
    "    \n",
    "#     if len(coords) == 3:\n",
    "#         atlasq_cmd = os.path.join(scripts_dir,\"atlasq.sh\")\n",
    "#         atlasq = Command().init_cmd(atlasq_cmd)\n",
    "#         atlasq.append(f\"--coord\")\n",
    "#         atlasq.append(f\"\\\"{coords[0]},{coords[1]},{coords[2]}\\\"\")\n",
    "#         # atlasq.append(f\"--atlas=\\\"{vol_atlas}\\\"\")\n",
    "    \n",
    "#         run(atlasq,out_file)\n",
    "\n",
    "#         with open(out_file,\"r\") as file:\n",
    "#             text = file.readlines()\n",
    "#             for i in range(0,len(text)):\n",
    "#                 text[i] = re.sub(f\"<b>{vol_atlas}</b><br>\",\"\",text[i].rstrip())\n",
    "\n",
    "#         os.remove(out_file)\n",
    "        \n",
    "#         if len(text) == 0:\n",
    "#             pass\n",
    "#         else:\n",
    "#             roi_list.extend(text) \n",
    "        \n",
    "#     return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vol_clust(nii_file,thresh=1.77,dist=20,vol_atlas=\"Harvard-Oxford Subcortical Structural Atlas\"):\n",
    "#     '''\n",
    "#     Identifies clusters in a volumetric (NIFTI) file (specifically for subcortical volumes).\n",
    "    \n",
    "#     Arguments:\n",
    "#         nii_file(file): Input NIFTI file\n",
    "#         thresh(float): Cluster minimum threshold\n",
    "#         dist(float): Minimum distance between clusters\n",
    "#         vol_atlas(str): Atlas to be used in FSL's `atlasquery`. See FSL's `atlasquery` help menu for details.\n",
    "#     Returns:\n",
    "#         roi_list(list): List of ROIs that overlap with some given cluster\n",
    "#     '''\n",
    "    \n",
    "#     out_file = \"vol.cluster.tsv\"\n",
    "    \n",
    "#     roi_list = list()\n",
    "#     tmp_list = list()\n",
    "    \n",
    "#     vol_clust = Command().init_cmd(\"cluster\")\n",
    "    \n",
    "#     vol_clust.append(f\"--in={nii_file}\")\n",
    "#     vol_clust.append(f\"--thresh={thresh}\")\n",
    "#     vol_clust.append(f\"--peakdist={dist}\")\n",
    "#     vol_clust.append(\"--mm\")\n",
    "    \n",
    "#     run(vol_clust,out_file)\n",
    "    \n",
    "#     df_tmp = pd.read_csv(out_file,sep=\"\\t\")\n",
    "    \n",
    "#     os.remove(out_file)\n",
    "    \n",
    "#     df = df_tmp[['MAX X (mm)','MAX Y (mm)','MAX Z (mm)']].copy()\n",
    "    \n",
    "#     for i in range(0,len(df)):\n",
    "#         coord_list=[df['MAX X (mm)'][i],df['MAX Y (mm)'][i],df['MAX Z (mm)'][i]]\n",
    "#         tmp_list = roi_loc(coord_list,vol_atlas)\n",
    "#         if len(tmp_list) == 0:\n",
    "#             pass\n",
    "#         else:\n",
    "#             roi_list.extend(tmp_list)\n",
    "    \n",
    "#     return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vol_data(file,thresh=1.77,dist=20,vol_atlas_num=4,nii_atlas = \"\",atlas_info = \"\"):\n",
    "    '''\n",
    "    Creates (subcortical) NIFTI volumetric data from input CIFTI, followed by identifying the ROIs that\n",
    "    are overlapped by clusters.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input CIFTI file\n",
    "        thresh(float): Cluster minimum threshold\n",
    "        dist(float): Minimum distance between clusters\n",
    "        vol_atlas_num(int): Atlas to be used in FSL's `atlasquery`. Number corresponds to an atlas. See FSL's `atlasquery` help menu for details.\n",
    "        nii_atlas(NIFTI file): NIFTI atlas file\n",
    "        atlas_info(file): Corresponding CSV key, value pairs of ROIs for atlas file\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs that overlap with some given cluster\n",
    "    '''\n",
    "    \n",
    "    vol_data = 'data.nii.gz'\n",
    "    \n",
    "    load_vol = Command().init_cmd(\"wb_command\"); load_vol.append(\"-cifti-separate\")\n",
    "    \n",
    "    load_vol.append(file)\n",
    "    load_vol.append(\"COLUMN\")\n",
    "    load_vol.append(\"-volume-all\")\n",
    "    load_vol.append(vol_data)\n",
    "    \n",
    "    run(load_vol)\n",
    "    \n",
    "    if nii_atlas and atlas_info:\n",
    "        # Read atlas data and info\n",
    "        [atlas_data,atlas_dict] = nro.load_atlas_data(nii_atlas,atlas_info)\n",
    "\n",
    "        # Read NIFTI data and find clusters\n",
    "        img_data = nro.load_nii_vol(vol_data,thresh,dist)\n",
    "\n",
    "        # Identify cluster and ROI overlaps\n",
    "        roi_list = nro.get_roi_name(img_data,atlas_data,atlas_dict)\n",
    "    else:\n",
    "        roi_list = nro.vol_clust(vol_data,thresh,dist,vol_atlas_num)\n",
    "    \n",
    "    os.remove(vol_data)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_stat_cluster(cii_file,cii_atlas,out_file,left_surf,right_surf,thresh=1.77,distance=20,vol_atlas_num=4,nii_atlas = \"\",atlas_info = \"\"):\n",
    "    '''\n",
    "    Identifies ROIs that have overlap with some cluster(s) from the input CIFTI file.\n",
    "    \n",
    "    Arguments:\n",
    "        cii_file(file): Input CIFTI dscalar file\n",
    "        cii_atlas(file): Input CIFTI dlabel (atlas) file\n",
    "        out_file(file): Name for output CSV file\n",
    "        left_surf(file): Left surface file (preferably midthickness file)\n",
    "        right_surf(file): Rigth surface file (preferably midthickness file)\n",
    "        thresh(float): Threshold values below this value\n",
    "        distance(float): Minimum distance between two or more clusters\n",
    "        vol_atlas_num(int): Atlas to be used in FSL's `atlasquery`. Number corresponds to an atlas. See FSL's `atlasquery` help menu for details.\n",
    "        nii_atlas(NIFTI file): NIFTI atlas file\n",
    "        atlas_info(file): Corresponding CSV key, value pairs of ROIs for atlas file\n",
    "    Returns:\n",
    "        out_file(file): Output CSV file\n",
    "    '''\n",
    "    \n",
    "    # Isolate cluster data\n",
    "    cii_data = find_clusters(cii_file,left_surf,right_surf,thresh,distance)\n",
    "    \n",
    "    # Significant cluster overlap ROI list\n",
    "    roi_list = list()\n",
    "    tmp_list = list()\n",
    "    \n",
    "    # Iterate through wb_structures\n",
    "    wb_structs = [\"CORTEX_LEFT\",\"CORTEX_RIGHT\"]\n",
    "    \n",
    "    for wb_struct in wb_structs:\n",
    "        tmp_list = proc_hemi(cii_data,cii_atlas,wb_struct)\n",
    "        if len(tmp_list) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            roi_list.extend(tmp_list)\n",
    "    \n",
    "    os.remove(cii_data)\n",
    "    \n",
    "    if platform.system().lower() != 'windows':\n",
    "        tmp_list = load_vol_data(cii_file,thresh,distance,vol_atlas_num,nii_atlas,atlas_info)\n",
    "    \n",
    "    if len(tmp_list) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        roi_list.extend(tmp_list)\n",
    "    \n",
    "    # Write output spreadsheet of ROIs\n",
    "    if len(roi_list) != 0:\n",
    "        out_file = write_spread(cii_file,out_file,roi_list)\n",
    "        \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cii_1 = \"files.test/dr_stage3_ic0012_tfce_tstat_fwep_c2.dscalar.nii\"\n",
    "cii_2 = \"files.test/dr_stage3_ic0009_tfce_tstat_fwep_c2.dscalar.nii\"\n",
    "cii_atlas = \"files.test/cvs_avg35_inMNI152.aparc.32k_fs_LR.dlabel.nii\"\n",
    "out_file = \"test.4.csv\"\n",
    "surf_l = \"files.test/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii\"\n",
    "surf_r = \"files.test/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\"\n",
    "thresh = 1.77\n",
    "distance = 20\n",
    "vol_atlas = 4\n",
    "nii_atlas = \"nifti_roi/files.atlases/Atlas_ROIs.2.nii.gz\"\n",
    "atlas_info = \"nifti_roi/files.atlases/Atlas_ROIs.2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adebayo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: get_labeltable method deprecated. Use the gifti_img.labeltable property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "/home/adebayo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: get_labeltable method deprecated. Use the gifti_img.labeltable property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test.4.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_stat_cluster(cii_1,cii_atlas,out_file,surf_l,surf_r,thresh,distance,4,nii_atlas,atlas_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adebayo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: get_labeltable method deprecated. Use the gifti_img.labeltable property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "/home/adebayo/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: get_labeltable method deprecated. Use the gifti_img.labeltable property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test.4.csv'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_stat_cluster(cii_file=cii_2,cii_atlas=cii_atlas,out_file=out_file,left_surf=surf_l,right_surf=surf_r,thresh=thresh,distance=distance,vol_atlas_num=4,nii_atlas=nii_atlas,atlas_info=atlas_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Atlas Numbers (for atlasquery wrapper) \n",
      "    \n",
      "    1.  Cerebellar Atlas in MNI152 space after normalization with FLIRT \n",
      "    2.  Cerebellar Atlas in MNI152 space after normalization with FNIRT \n",
      "    3.  Harvard-Oxford Cortical Structural Atlas \n",
      "    4.  Harvard-Oxford Subcortical Structural Atlas \n",
      "    5.  Human Sensorimotor Tracts Labels \n",
      "    6.  JHU ICBM-DTI-81 White-Matter Labels \n",
      "    7.  JHU White-Matter Tractography Atlas \n",
      "    8.  Juelich Histological Atlas \n",
      "    9.  MNI Structural Atlas \n",
      "    10. Mars Parietal connectivity-based parcellation \n",
      "    11. Mars TPJ connectivity-based parcellation \n",
      "    12. Neubert Ventral Frontal connectivity-based parcellation \n",
      "    13. Oxford Thalamic Connectivity Probability Atlas \n",
      "    14. Oxford-Imanova Striatal Connectivity Atlas 3 sub-regions \n",
      "    15. Oxford-Imanova Striatal Connectivity Atlas 7 sub-regions \n",
      "    16. Oxford-Imanova Striatal Structural Atlas \n",
      "    17. Sallet Dorsal Frontal connectivity-based parcellation \n",
      "    18. Subthalamic Nucleus Atlas \n",
      "    19. Talairach Daemon Labels \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nro.print_atlases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
