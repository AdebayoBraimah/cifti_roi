{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Command():\n",
    "    '''\n",
    "    Creates a command and an empty command list for UNIX command line programs/applications. Primary use and\n",
    "    use-cases are intended for the subprocess module and its associated classes (i.e. run).\n",
    "    Attributes:\n",
    "        command: Command to be performed on the command line\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init doc-string for Command class.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def init_cmd(self, command):\n",
    "        '''\n",
    "        Init command function for initializing commands to be used on UNIX command line.\n",
    "        \n",
    "        Arguments:\n",
    "            command (string): Command to be used. Note: command used must be in system path\n",
    "        Returns:\n",
    "            cmd_list (list): Mutable list that can be appended to.\n",
    "        '''\n",
    "        self.command = command\n",
    "        self.cmd_list = [f\"{self.command}\"]\n",
    "        return self.cmd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cmd_list,stdout=\"\",stderr=\"\"):\n",
    "    '''\n",
    "    Uses python's built-in subprocess class to run a command from an input command list.\n",
    "    The standard output and error can optionally be written to file.\n",
    "    \n",
    "    Arguments:\n",
    "        cmd_list(list): Input command list to be run from the UNIX command line.\n",
    "        stdout(file): Output file to write standard output to.\n",
    "        stderr(file): Output file to write standard error to.\n",
    "    Returns:\n",
    "        stdout(file): Output file that contains the standard output.\n",
    "        stderr(file): Output file that contains the standard error.\n",
    "    '''\n",
    "    if stdout and stderr:\n",
    "        with open(stdout,\"w\") as file:\n",
    "            with open(stderr,\"w\") as file_err:\n",
    "                subprocess.call(cmd_list,stdout=file,stderr=file_err)\n",
    "                file.close(); file_err.close()\n",
    "    elif stdout:\n",
    "        with open(stdout,\"w\") as file:\n",
    "            subprocess.call(cmd_list,stdout=file)\n",
    "            file.close()\n",
    "    else:\n",
    "        subprocess.call(cmd_list)\n",
    "\n",
    "    return stdout,stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"cvs_avg35_inMNI152.aparc.32k_fs_LR.dlabel.nii\"\n",
    "# wb_struct = \"CORTEX_LEFT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gii_label = 'data.label.gii'\n",
    "    \n",
    "# load_label = Command().init_cmd(\"wb_command\"); load_label.append(\"-cifti-separate\")\n",
    "\n",
    "# load_label.append(file)\n",
    "# load_label.append(\"COLUMN\")\n",
    "# load_label.append(\"-label\"); load_label.append(wb_struct)\n",
    "# load_label.append(gii_label)\n",
    "\n",
    "# # subprocess.call(load_label)\n",
    "\n",
    "# load_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(load_label,'test.log.txt','test.err.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hemi_labels(file,wb_struct,map_number=1):\n",
    "    '''\n",
    "    Loads left or right hemisphere of CIFTI dlabel (dense label) file.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input CIFTI dlabel file\n",
    "        wb_struct(str): Structure - valid inputs are either: CORTEX_LEFT or CORTEX_RIGHT\n",
    "        map_number(int): Map number of the input CIFTI dlabel map\n",
    "    Returns:\n",
    "        atlas_data(numpy array): Numpy array of labeled surface vertices for some specific hemisphere\n",
    "        atlas_dict(dict): Dictionary of label IDs to ROI names\n",
    "    '''\n",
    "    \n",
    "    gii_label = 'data.label.gii'\n",
    "    \n",
    "    load_label = Command().init_cmd(\"wb_command\"); load_label.append(\"-cifti-separate\")\n",
    "    \n",
    "    load_label.append(file)\n",
    "    load_label.append(\"COLUMN\")\n",
    "    load_label.append(\"-label\"); load_label.append(wb_struct)\n",
    "    load_label.append(gii_label)\n",
    "    \n",
    "    run(load_label)\n",
    "    \n",
    "    gifti_img = nib.load(gii_label)\n",
    "    \n",
    "    atlas_data = gifti_img.get_arrays_from_intent('NIFTI_INTENT_LABEL')[map_number-1].data\n",
    "    atlas_dict = gifti_img.get_labeltable().get_labels_as_dict()\n",
    "    \n",
    "    os.remove(gii_label)\n",
    "    \n",
    "    return atlas_data,atlas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gii_data(file,intent='NIFTI_INTENT_NORMAL'):\n",
    "    '''\n",
    "    Loads GIFTI surface/metric data (.func or .shape) and stores the \n",
    "    data as NxMxP numpy array - in which N = X dimensions, M = Y \n",
    "    dimensions, and P = the number of TRs or timepoints of the input \n",
    "    GIFTI data.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input GIFTI surface/metric file\n",
    "        intent(str): File read intention for nibabel i/o module\n",
    "    Returns:\n",
    "        data(numpy array): Numpy array of data for GIFTI file\n",
    "    '''\n",
    "    \n",
    "    # Load surface data\n",
    "    surf_dist_nib = nib.load(file)\n",
    "    \n",
    "    # Number of TRs in data\n",
    "    num_da = surf_dist_nib.numDA\n",
    "    \n",
    "    # Read all arrays and concatenate temporally\n",
    "    array1 = surf_dist_nib.get_arrays_from_intent(intent)[0]\n",
    "    \n",
    "    data = array1.data\n",
    "    \n",
    "    if num_da >= 1:\n",
    "        for da in range(1,num_da):\n",
    "            data = np.vstack((data,surf_dist_nib.get_arrays_from_intent(intent)[da].data))\n",
    "            \n",
    "    # Transpose data such that vertices are organized by TR\n",
    "    data = np.transpose(data)\n",
    "    \n",
    "    # If output is 1D, make it 2D\n",
    "    if len(data.shape) == 1:\n",
    "        data = data.reshape(data.shape[0],1)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hemi_data(file,wb_struct):\n",
    "    '''\n",
    "    Wrapper function for `load_gii_data`:\n",
    "    Loads GIFTI surface/metric data (.func or .shape) and stores the \n",
    "    data as NxMxP numpy array - in which N = X dimensions, M = Y \n",
    "    dimensions, and P = the number of TRs or timepoints of the input \n",
    "    GIFTI data.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input GIFTI surface/metric file\n",
    "        wb_struct(str): Structure - valid inputs are either: CORTEX_LEFT or CORTEX_RIGHT\n",
    "    Returns:\n",
    "        data(numpy array): Numpy array of data for GIFTI file\n",
    "    '''\n",
    "    \n",
    "    gii_data = 'data.func.gii'\n",
    "    \n",
    "    load_gii = Command().init_cmd(\"wb_command\"); load_gii.append(\"-cifti-separate\")\n",
    "    \n",
    "    load_gii.append(file)\n",
    "    load_gii.append(\"COLUMN\")\n",
    "    load_gii.append(\"-metric\"); load_gii.append(wb_struct)\n",
    "    load_gii.append(gii_data)\n",
    "    \n",
    "    run(load_gii)\n",
    "    \n",
    "    data = load_gii_data(gii_data)\n",
    "    \n",
    "    os.remove(gii_data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_name(cluster_data,atlas_data,atlas_dict):\n",
    "    '''\n",
    "    Finds ROI names from overlapping clusters on the cortical surface via\n",
    "    vertex matching.\n",
    "    \n",
    "    Arguments:\n",
    "        cluster_data(numpy array): Input CIFTI dlabel file\n",
    "        atlas_data(numpy array): Numpy array of labeled surface vertices for some specific hemisphere\n",
    "        atlas_dict(dict): Dictionary of label IDs to ROI names\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs overlapped by cluster(s)\n",
    "    '''\n",
    "    \n",
    "    # for idx,val in enumerate(cluster_data.astype(int)):\n",
    "    for idx,val in enumerate(cluster_data):\n",
    "        if cluster_data[idx] == 0:\n",
    "            atlas_data[idx] = 0\n",
    "    \n",
    "    tmp_list = list()\n",
    "    roi_list = list()\n",
    "    \n",
    "    for i in np.unique(atlas_data)[1:]:\n",
    "        # print(atlas_dict[i])\n",
    "        tmp_list = atlas_dict[i]\n",
    "        roi_list.append(tmp_list)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters(file,left_surf,right_surf,thresh = 1.77,distance = 20):\n",
    "    '''\n",
    "    Loads left or right hemisphere of CIFTI dscalar (dense scalar) file and identifies clusters\n",
    "    and returns a numpy array of the clusters' vertices.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input CIFTI dscalar file\n",
    "        left_surf(file): Left surface file (preferably midthickness file)\n",
    "        right_surf(file): Rigth surface file (preferably midthickness file)\n",
    "        thresh(float): Threshold values below this value\n",
    "        distance(float): Minimum distance between two or more clusters\n",
    "    Returns:\n",
    "        cii_data(numpy array): Numpy array of surface vertices\n",
    "    '''\n",
    "    \n",
    "    cii_data = 'clusters.dscalar.nii'\n",
    "    \n",
    "    thresh = str(thresh)\n",
    "    distance = str(distance)\n",
    "    \n",
    "    find_cluster = Command().init_cmd(\"wb_command\"); find_cluster.append(\"-cifti-find-clusters\")\n",
    "    find_cluster.append(file)\n",
    "    find_cluster.append(thresh); find_cluster.append(distance)\n",
    "    find_cluster.append(thresh); find_cluster.append(distance)\n",
    "    find_cluster.append(\"COLUMN\")\n",
    "    find_cluster.append(cii_data)\n",
    "    find_cluster.append(\"-left-surface\")\n",
    "    find_cluster.append(left_surf)\n",
    "    find_cluster.append(\"-right-surface\")\n",
    "    find_cluster.append(right_surf)\n",
    "    \n",
    "    run(find_cluster)\n",
    "    \n",
    "    return cii_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spread(file,out_file,roi_list):\n",
    "    '''\n",
    "    Writes the contents or roi_list to a spreadsheet.\n",
    "    \n",
    "    Arguments:\n",
    "        file (file): Input CIFTI file\n",
    "        out_file (file): Output csv file name and path. This file need not exist at runtime.\n",
    "        roi_list(list): List of ROIs to write to file\n",
    "    Returns: \n",
    "        out_file (csv file): Output csv file name and path.\n",
    "    '''\n",
    "    \n",
    "    # Strip csv file extension from output file name\n",
    "    if '.csv' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    elif '.tsv' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    elif '.txt' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Construct image dictionary\n",
    "    file = os.path.abspath(file)\n",
    "    img_dict = {\"File\":file,\n",
    "         \"ROIs\":[roi_list]}\n",
    "    \n",
    "    # Create dataframe from image dictionary\n",
    "    df = pd.DataFrame.from_dict(img_dict,orient='columns')\n",
    "    \n",
    "    # Write output CSV file\n",
    "    if os.path.exists(out_file):\n",
    "        df.to_csv(out_file, sep=\",\", header=False, index=False, mode='a')\n",
    "    else:\n",
    "        df.to_csv(out_file, sep=\",\", header=True, index=False, mode='w')\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_hemi(gii_data, gii_atlas, wb_struct):\n",
    "    '''\n",
    "    Wrapper function for `load_hemi_labels`, `load_hemi_data`, and `get_roi_name`:\n",
    "    \n",
    "    Loads GIFTI data to find the names or ROIs that overlap with clusters for some hemisphere\n",
    "    \n",
    "    Arguments:\n",
    "        gii_data(file): Input GIFTI file\n",
    "        gii_atlas(file): Input GIFTI atlas label file\n",
    "        wb_struct(str): Structure - valid inputs are either: CORTEX_LEFT or CORTEX_RIGHT\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs that overlap with CIFTI cluster\n",
    "    '''\n",
    "       \n",
    "    \n",
    "    # Get atlas information\n",
    "    [atlas_data,atlas_dict] = load_hemi_labels(gii_atlas,wb_struct)\n",
    "    \n",
    "    # Get cluster data\n",
    "    cluster_data = load_hemi_data(gii_data, wb_struct)\n",
    "    \n",
    "    # Get ROI names from overlapping cluster(s)\n",
    "    roi_list = get_roi_name(cluster_data,atlas_data,atlas_dict)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cii_data = 'clusters.dscalar.nii' # this exists for testing purposes\n",
    "# cii_atlas = \"../cvs_avg35_inMNI152.aparc.32k_fs_LR.dlabel.nii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc_hemi(cii_data,cii_atlas,\"CORTEX_RIGHT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proc_hemi(cii_data,cii_atlas,\"CORTEX_LEFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_stat_cluster(cii_file,cii_atlas,out_file,left_surf,right_surf,thresh=1.77,distance=20,vol_atlas=\"Harvard-Oxford Subcortical Structural Atlas\"):\n",
    "    '''\n",
    "    Identifies ROIs that have overlap with some cluster(s) from the input CIFTI file.\n",
    "    \n",
    "    Arguments:\n",
    "        cii_file(file): Input CIFTI dscalar file\n",
    "        cii_atlas(file): Input CIFTI dlabel (atlas) file\n",
    "        out_file(file): Name for output CSV file\n",
    "        left_surf(file): Left surface file (preferably midthickness file)\n",
    "        right_surf(file): Rigth surface file (preferably midthickness file)\n",
    "        thresh(float): Threshold values below this value\n",
    "        distance(float): Minimum distance between two or more clusters\n",
    "        vol_atlas(str): Atlas to be used in FSL's `atlasquery`. See FSL's `atlasquery` help menu for details.\n",
    "    Returns:\n",
    "        out_file(file): Output CSV file\n",
    "    '''\n",
    "    \n",
    "    # Isolate cluster data\n",
    "    cii_data = find_clusters(cii_file,left_surf,right_surf,thresh,distance)\n",
    "    \n",
    "    # Significant cluster overlap ROI list\n",
    "    roi_list = list()\n",
    "    tmp_list = list()\n",
    "    \n",
    "    # Iterate through wb_structures\n",
    "    wb_structs = [\"CORTEX_LEFT\",\"CORTEX_RIGHT\"]\n",
    "    \n",
    "    for wb_struct in wb_structs:\n",
    "        tmp_list = proc_hemi(cii_data,cii_atlas,wb_struct)\n",
    "        # roi_list.append(tmp_list)\n",
    "        # roi_list.extend(tmp_list)\n",
    "        if len(tmp_list) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            roi_list.extend(tmp_list)\n",
    "    \n",
    "    os.remove(cii_data)\n",
    "    \n",
    "    if platform.system().lower() != 'windows':\n",
    "        tmp_list = load_vol_data(cii_file,thresh,distance,vol_atlas)\n",
    "    \n",
    "    if len(tmp_list) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        roi_list.extend(tmp_list)\n",
    "    \n",
    "    # Write output spreadsheet of ROIs\n",
    "    if len(roi_list) != 0:\n",
    "        out_file = write_spread(cii_file,out_file,roi_list)\n",
    "        \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nifti volume cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes that the CIFTI volumetric data is in MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vol_data(file,thresh=1.77,dist=20,vol_atlas=\"Harvard-Oxford Subcortical Structural Atlas\"):\n",
    "    '''\n",
    "    Creates (subcortical) NIFTI volumetric data from input CIFTI, followed by identifying the ROIs that\n",
    "    are overlapped by clusters.\n",
    "    \n",
    "    Arguments:\n",
    "        file(file): Input CIFTI file\n",
    "        thresh(float): Cluster minimum threshold\n",
    "        dist(float): Minimum distance between clusters\n",
    "        vol_atlas(str): Atlas to be used in FSL's `atlasquery`. See FSL's `atlasquery` help menu for details.\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs that overlap with some given cluster\n",
    "    '''\n",
    "    \n",
    "    vol_data = 'data.nii.gz'\n",
    "    \n",
    "    load_vol = Command().init_cmd(\"wb_command\"); load_vol.append(\"-cifti-separate\")\n",
    "    \n",
    "    load_vol.append(file)\n",
    "    load_vol.append(\"COLUMN\")\n",
    "    load_vol.append(\"-volume-all\")\n",
    "    load_vol.append(vol_data)\n",
    "    \n",
    "    run(load_vol)\n",
    "    \n",
    "    roi_list = vol_clust(vol_data,thresh,dist,vol_atlas)\n",
    "    \n",
    "    os.remove(vol_data)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vol_clust(nii_file,thresh=1.77,dist=20,vol_atlas=\"Harvard-Oxford Subcortical Structural Atlas\"):\n",
    "    '''\n",
    "    Identifies clusters in a volumetric (NIFTI) file (specifically for subcortical volumes).\n",
    "    \n",
    "    Arguments:\n",
    "        nii_file(file): Input NIFTI file\n",
    "        thresh(float): Cluster minimum threshold\n",
    "        dist(float): Minimum distance between clusters\n",
    "        vol_atlas(str): Atlas to be used in FSL's `atlasquery`. See FSL's `atlasquery` help menu for details.\n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs that overlap with some given cluster\n",
    "    '''\n",
    "    \n",
    "    out_file = \"vol.cluster.tsv\"\n",
    "    \n",
    "    roi_list = list()\n",
    "    tmp_list = list()\n",
    "    \n",
    "    vol_clust = Command().init_cmd(\"cluster\")\n",
    "    \n",
    "    vol_clust.append(f\"--in={nii_file}\")\n",
    "    vol_clust.append(f\"--thresh={thresh}\")\n",
    "    vol_clust.append(f\"--peakdist={dist}\")\n",
    "    vol_clust.append(\"--mm\")\n",
    "    \n",
    "    run(vol_clust,out_file)\n",
    "    \n",
    "    df_tmp = pd.read_csv(out_file,sep=\"\\t\")\n",
    "    \n",
    "    os.remove(out_file)\n",
    "    \n",
    "    df = df_tmp[['MAX X (mm)','MAX Y (mm)','MAX Z (mm)']].copy()\n",
    "    \n",
    "    for i in range(0,len(df)):\n",
    "        coord_list=[df['MAX X (mm)'][i],df['MAX Y (mm)'][i],df['MAX Z (mm)'][i]]\n",
    "        tmp_list = roi_loc(coord_list,vol_atlas)\n",
    "        if len(tmp_list) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            roi_list.extend(tmp_list)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nii_file = \"sphere_rois.nii.gz\"; thresh=1.00; dist=20; out_file = \"vol.cluster.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_file = \"vol.cluster.tsv\"\n",
    "\n",
    "# vol_clust = Command().init_cmd(\"cluster\")\n",
    "\n",
    "# vol_clust.append(f\"--in={nii_file}\")\n",
    "# vol_clust.append(f\"--thresh={thresh}\")\n",
    "# vol_clust.append(f\"--peakdist={dist}\")\n",
    "# vol_clust.append(\"--mm\")\n",
    "# # vol_clust.append(\">\")\n",
    "# # vol_clust.append(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vol_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"test.tsv\",sep=\"\\t\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['COG X (mm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df2 = df[['COG X (mm)','COG Y (mm)','COG Z (mm)']].copy()\n",
    "# df2 = df[['MAX X (mm)','MAX Y (mm)','MAX Z (mm)']].copy()\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(df2)):\n",
    "#     print(df2['MAX X (mm)'][i],df2['MAX Y (mm)'][i],df2['MAX Z (mm)'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_loc(coords,vol_atlas=\"Harvard-Oxford Subcortical Structural Atlas\"):\n",
    "    '''\n",
    "    Uses input list of X,Y,Z MNI space mm coordinates to identify ROIs.\n",
    "    \n",
    "    Arguments:\n",
    "        coords(list): Coordinate list with a lenth of 3 that corresponds to the XYZ coordinates of some ROI in MNI space.\n",
    "        vol_atlas(str): Atlas to be used in FSL's `atlasquery`. See FSL's `atlasquery` help menu for details.\n",
    "        \n",
    "    Returns:\n",
    "        roi_list(list): List of ROIs generated from input coordinates.\n",
    "    '''\n",
    "    \n",
    "    roi_list = list()\n",
    "    out_file = \"subcort.rois.txt\"\n",
    "    \n",
    "    if len(coords) == 3:\n",
    "        atlasq = Command().init_cmd(\"atlasquery\")\n",
    "        atlasq.append(f\"--atlas=\\\"{vol_atlas}\\\"\")\n",
    "        atlasq.append(f\"--coord={coords[0]},{coords[1]},{coords[2]}\")\n",
    "    \n",
    "        run(atlasq,out_file)\n",
    "\n",
    "        with open(out_file,\"r\") as file:\n",
    "            text = file.readlines()\n",
    "            for i in range(0,len(text)):\n",
    "                text[i] = re.sub(f\"<b>{vol_atlas}</b><br>\",\"\",text[i].rstrip())\n",
    "\n",
    "        os.remove(out_file)\n",
    "        \n",
    "        if len(text) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            roi_list.extend(text) \n",
    "        \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords = [30 , 21, 45]\n",
    "# vol_atlas=\"Harvard-Oxford Subcortical Structural Atlas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlasq = Command().init_cmd(\"atlasquery\")\n",
    "# atlasq.append(f\"--atlas=\\\"{vol_atlas}\\\"\")\n",
    "# atlasq.append(f\"--coord={coords[0]},{coords[1]},{coords[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlasq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"subcort.rois.txt\",\"r\") as file:\n",
    "#     text = file.readlines()\n",
    "#     for i in range(0,len(text)):\n",
    "#         text[i] = re.sub(f\"<b>{vol_atlas}</b><br>\",\"\",text[i].rstrip())\n",
    "        \n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vol_atlas=\"Harvard-Oxford Subcortical Structural Atlas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.sub(f\"<b>{vol_atlas}</b><br>\",\"\",text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range(0,len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = [text[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_list = []\n",
    "# roi_list.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_list.append(text[1])\n",
    "# roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = ['fat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
