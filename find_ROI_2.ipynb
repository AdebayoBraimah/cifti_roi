{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Command():\n",
    "    '''\n",
    "    Creates a command and an empty command list for UNIX command line programs/applications. Primary use and\n",
    "    use-cases are intended for the subprocess module and its associated classes (i.e. run).\n",
    "    Attributes:\n",
    "        command: Command to be performed on the command line\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Init doc-string for Command class.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def init_cmd(self, command):\n",
    "        '''\n",
    "        Init command function for initializing commands to be used on UNIX command line.\n",
    "        Arguments:\n",
    "            command (string): Command to be used. Note: command used must be in system path\n",
    "        Returns:\n",
    "            cmd_list (list): Mutable list that can be appended to.\n",
    "        '''\n",
    "        self.command = command\n",
    "        self.cmd_list = [f\"{self.command}\"]\n",
    "        return self.cmd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hemi_labels(file,wb_struct,map_number=1):\n",
    "    '''working doc-string'''\n",
    "    \n",
    "    gii_label = 'data.label.gii'\n",
    "    \n",
    "    load_label = Command().init_cmd(\"wb_command\"); load_label.append(\"-cifti-separate\")\n",
    "    \n",
    "    load_label.append(file)\n",
    "    load_label.append(\"COLUMN\")\n",
    "    load_label.append(\"-label\"); load_label.append(wb_struct)\n",
    "    load_label.append(gii_label)\n",
    "    \n",
    "    subprocess.call(load_label)\n",
    "    \n",
    "    gifti_img = nib.load(gii_label)\n",
    "    \n",
    "    atlas_data = gifti_img.get_arrays_from_intent('NIFTI_INTENT_LABEL')[1-1].data\n",
    "    atlas_dict = gifti_img.get_labeltable().get_labels_as_dict()\n",
    "    \n",
    "    os.remove(gii_label)\n",
    "    \n",
    "    return atlas_data,atlas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gii_data(file,intent='NIFTI_INTENT_NORMAL'):\n",
    "    '''working doc-string'''\n",
    "    \n",
    "    # Load surface data\n",
    "    surf_dist_nib = nib.load(file)\n",
    "    \n",
    "    # Number of TRs in data\n",
    "    num_da = surf_dist_nib.numDA\n",
    "    \n",
    "    # Read all arrays and concatenate temporally\n",
    "    array1 = surf_dist_nib.get_arrays_from_intent(intent)[0]\n",
    "    \n",
    "    data = array1.data\n",
    "    \n",
    "    if num_da >= 1:\n",
    "        for da in range(1,num_da):\n",
    "            data = np.vstack((data,surf_dist_nib.get_arrays_from_intent(intent)[da].data))\n",
    "            \n",
    "    # Transpose data such that vertices are organized by TR\n",
    "    data = np.transpose(data)\n",
    "    \n",
    "    # If output is 1D, make it 2D\n",
    "    if len(data.shape) == 1:\n",
    "        data = data.reshape(data.shape[0],1)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hemi_data(file,wb_struct):\n",
    "    '''working doc-string'''\n",
    "    \n",
    "    gii_data = 'data.func.gii'\n",
    "    \n",
    "    load_gii = Command().init_cmd(\"wb_command\"); load_gii.append(\"-cifti-separate\")\n",
    "    \n",
    "    load_gii.append(file)\n",
    "    load_gii.append(\"COLUMN\")\n",
    "    load_gii.append(\"-metric\"); load_gii.append(wb_struct)\n",
    "    load_gii.append(gii_data)\n",
    "    \n",
    "    subprocess.call(load_gii)\n",
    "    \n",
    "    data = load_gii_data(gii_data)\n",
    "    \n",
    "    os.remove(gii_data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi_name(cluster_data,atlas_data,atlas_dict):\n",
    "    '''working doc-string'''\n",
    "    \n",
    "    # for idx,val in enumerate(cluster_data.astype(int)):\n",
    "    for idx,val in enumerate(cluster_data):\n",
    "        if cluster_data[idx] == 0:\n",
    "            atlas_data[idx] = 0\n",
    "    \n",
    "    tmp_list = list()\n",
    "    roi_list = list()\n",
    "    \n",
    "    for i in np.unique(atlas_data)[1:]:\n",
    "        # print(atlas_dict[i])\n",
    "        tmp_list = atlas_dict[i]\n",
    "        roi_list.append(tmp_list)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters(file,left_surf,right_surf,thresh = 1.77,distance = 20):\n",
    "    '''working doc-string'''\n",
    "    \n",
    "    cii_data = 'clusters.dscalar.nii'\n",
    "    \n",
    "    thresh = str(thresh)\n",
    "    distance = str(distance)\n",
    "    \n",
    "    find_cluster = Command().init_cmd(\"wb_command\"); find_cluster.append(\"-cifti-find-clusters\")\n",
    "    find_cluster.append(file)\n",
    "    find_cluster.append(thresh); find_cluster.append(distance)\n",
    "    find_cluster.append(thresh); find_cluster.append(distance)\n",
    "    find_cluster.append(\"COLUMN\")\n",
    "    find_cluster.append(cii_data)\n",
    "    find_cluster.append(\"-left-surface\")\n",
    "    find_cluster.append(left_surf)\n",
    "    find_cluster.append(\"-right-surface\")\n",
    "    find_cluster.append(right_surf)\n",
    "    \n",
    "    subprocess.call(find_cluster)\n",
    "    \n",
    "    return cii_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spread(file,out_file,roi_list):\n",
    "    '''\n",
    "    Writes image filename, dimensions, and acquisition direction to a\n",
    "    spreadsheet. If the spreadsheet already exists, then it is appended\n",
    "    to.\n",
    "    \n",
    "    Arguments:\n",
    "        nii_file (nifti file): NifTi image filename with absolute filepath.\n",
    "        out_file (csv file): Output csv file name and path. This file need not exist at runtime.\n",
    "        \n",
    "    Returns: \n",
    "        out_file (csv file): Output csv file name and path.\n",
    "    '''\n",
    "    \n",
    "    # Strip csv file extension from output file name\n",
    "    if '.csv' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    elif '.tsv' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    elif '.txt' in out_file:\n",
    "        out_file = os.path.splitext(out_file)[0]\n",
    "        out_file = out_file + '.csv'\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Construct image dictionary\n",
    "    file = os.path.abspath(file)\n",
    "    img_dict = {\"File\":file,\n",
    "         \"ROIs\":[roi_list]}\n",
    "    \n",
    "    # Create dataframe from image dictionary\n",
    "    df = pd.DataFrame.from_dict(img_dict,orient='columns')\n",
    "    \n",
    "    # Write output CSV file\n",
    "    if os.path.exists(out_file):\n",
    "        df.to_csv(out_file, sep=\",\", header=False, index=False, mode='a')\n",
    "    else:\n",
    "        df.to_csv(out_file, sep=\",\", header=True, index=False, mode='w')\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_hemi(gii_data, gii_atlas, wb_struct):\n",
    "    '''working doc-string'''\n",
    "    \n",
    "    # Get atlas information\n",
    "    [atlas_data,atlas_dict] = load_hemi_labels(gii_atlas,wb_struct)\n",
    "    \n",
    "    # Get cluster data\n",
    "    cluster_data = load_hemi_data(gii_data, wb_struct)\n",
    "    \n",
    "    # Get ROI names from overlapping cluster(s)\n",
    "    roi_list = get_roi_name(cluster_data,atlas_data,atlas_dict)\n",
    "    \n",
    "    return roi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cii_data = 'clusters.dscalar.nii' # this exists for testing purposes\n",
    "cii_atlas = \"../cvs_avg35_inMNI152.aparc.32k_fs_LR.dlabel.nii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: get_labeltable method deprecated. Use the gifti_img.labeltable property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['R_inferiorparietal', 'R_precuneus', 'R_superiorparietal']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_hemi(cii_data,cii_atlas,\"CORTEX_RIGHT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: get_labeltable method deprecated. Use the gifti_img.labeltable property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_hemi(cii_data,cii_atlas,\"CORTEX_LEFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_stat_cluster(cii_file,cii_atlas,out_file,left_surf,right_surf,thresh=1.77,distance=20):\n",
    "    '''working doc-string'''\n",
    "    \n",
    "    # Isolate cluster data\n",
    "    cii_data = find_clusters(cii_file,left_surf,right_surf)\n",
    "    \n",
    "    # Significant cluster overlap ROI list\n",
    "    roi_list = list()\n",
    "    tmp_list = list()\n",
    "    \n",
    "    # Iterate through wb_structures\n",
    "    wb_structs = [\"CORTEX_LEFT\",\"CORTEX_RIGHT\"]\n",
    "    \n",
    "    for wb_struct in wb_structs:\n",
    "        tmp_list= proc_hemi(cii_data,cii_atlas,wb_struct)\n",
    "        # roi_list.append(tmp_list)\n",
    "        roi_list.extend(tmp_list)\n",
    "    \n",
    "    os.remove(cii_data)\n",
    "    \n",
    "    # Write output spreadsheet of ROIs\n",
    "    if len(roi_list) != 0:\n",
    "        out_file = write_spread(cii_file,out_file,roi_list)\n",
    "        \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
